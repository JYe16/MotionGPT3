# M2T Training with tunable generation parameters for better R-precision
# 
# 调参建议：
# 1. num_beams: 增加到 3-5 可能提升生成质量
# 2. temperature: 降低到 0.5-0.7 使输出更确定
# 3. max_gen_length: 增加到 60 可能包含更多细节
# 4. do_sample: False 使用贪婪/beam search, True 使用采样

NAME: Custom_M2T_Training_Tuned
ACCELERATOR: 'gpu'
DEVICE: [0]
NUM_NODES: 1

TEST:
  CHECKPOINTS: 'checkpoints/last.ckpt'
  SPLIT: test
  BATCH_SIZE: 64

TRAIN:
  STAGE: token_custom
  instruction_type: m2t
  BATCH_SIZE: 256
  END_EPOCH: 100
  LR_SCHEDULER:
    target: CosineAnnealingLR
    params:
      T_max: 200
      eta_min: 1e-6
  OPTIM:
    target: AdamW
    params:
      lr: 1e-4
      weight_decay: 0.01

DATASET:
  target: motGPT.data.HumanML3D_custom.HumanML3DDataModuleCustom
  CODE_PATH: motion_tokens_st_share
  HUMANML3D:
    ROOT: ../../llm-sensing/data/humanml3d_263/
    FPS: 20
    MIN_MOTION_LEN: 20
    MAX_MOTION_LEN: 196

model:
  target: motGPT.models.motgpt.MotGPT
  params:
    condition: 'motion'
    task: 'm2t'
    lm:
      target: motGPT.archs.mgpt_lm.MLM
      params:
        model_type: gpt2
        model_path: deps/gpt2
        stage: ${TRAIN.STAGE}
        ablation: ${ABLATION}
        motion_codebook_size: 512
        vocab_size: 512
        # =====================================================
        # 生成参数 - 调整这些来提升 R-precision
        # =====================================================
        # m2t_num_beams: 5        # beam search width
        # m2t_do_sample: False    # greedy/beam if False, sampling if True
        # m2t_temperature: 0.7    # lower = more deterministic
        # m2t_top_p: 0.9          # nucleus sampling threshold
        # m2t_max_length: 60      # max generated text length
    motion_vae:
      target: motGPT.archs.mld_vae.MldVae
      params:
        code_num: 512
        code_dim: 512
        nfeats: ${DATASET.NFEATS}
        ablation: ${ABLATION}
        datatype: ${DATASET.target}
        
LOSS:
  LAMBDA_CLS: 1.0

METRIC:
  TYPE: ['M2TMetrics']

LOGGER:
  TYPE: ['tensorboard']
  VAL_EVERY_STEPS: 1
